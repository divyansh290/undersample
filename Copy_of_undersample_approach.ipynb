{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divyansh290/undersample/blob/main/Copy_of_undersample_approach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfIq1H28o8bb",
        "outputId": "51205407-ab99-4487-e71c-f068eb2dd19f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 1s (4,510 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 123597 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract\n",
        "!tesseract --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtzPpj5UsE9b",
        "outputId": "82ccbd1c-5d73-461c-f64b-9e84763112e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n",
            "tesseract 4.1.1\n",
            " leptonica-1.82.0\n",
            "  libgif 5.1.9 : libjpeg 8d (libjpeg-turbo 2.1.1) : libpng 1.6.37 : libtiff 4.3.0 : zlib 1.2.11 : libwebp 1.2.2 : libopenjp2 2.4.0\n",
            " Found AVX2\n",
            " Found AVX\n",
            " Found FMA\n",
            " Found SSE\n",
            " Found libarchive 3.6.0 zlib/1.2.11 liblzma/5.2.5 bz2lib/1.0.8 liblz4/1.9.3 libzstd/1.4.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "er494WlJW74J"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import pytesseract\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40kFjSDCtku8",
        "outputId": "5c19cd07-6b3d-4ef9-e828-aa3e842e510e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "print(f\"Number of available CPU cores (threads): {multiprocessing.cpu_count()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4kJXRNkwYw_",
        "outputId": "2201d46e-653e-4f36-d1fb-804313779d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of available CPU cores (threads): 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/train.csv'  # Replace with your actual file path\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Create a directory to save the images\n",
        "image_dir = 'downloaded_images'\n",
        "os.makedirs(image_dir, exist_ok=True)\n",
        "\n",
        "# Function to download an image from a URL\n",
        "def download_image(row):\n",
        "    image_url = row['image_link']\n",
        "    image_name = f\"{row['group_id']}_{row.name}.jpg\"  # Unique image name using group_id and index\n",
        "    save_path = os.path.join(image_dir, image_name)\n",
        "\n",
        "    try:\n",
        "        response = requests.get(image_url, stream=True)\n",
        "        if response.status_code == 200:\n",
        "            with open(save_path, 'wb') as file:\n",
        "                for chunk in response.iter_content(1024):\n",
        "                    file.write(chunk)\n",
        "        return image_url, True  # Return URL and success status\n",
        "    except Exception as e:\n",
        "        return image_url, False  # Return URL and failure status\n",
        "\n",
        "# Number of threads to use\n",
        "num_threads = 80\n",
        "\n",
        "# Use ThreadPoolExecutor to download images in parallel\n",
        "with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "    futures = [executor.submit(download_image, row) for idx, row in data.iterrows()]\n",
        "\n",
        "    # Use tqdm to display progress\n",
        "    for future in tqdm(as_completed(futures), total=len(futures)):\n",
        "        url, success = future.result()\n",
        "        if not success:\n",
        "            print(f\"Failed to download {url}\")\n",
        "\n",
        "print(\"Image download complete.\")"
      ],
      "metadata": {
        "id": "EWL2WFMCtMhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "csv_file = \"/content/maximum_weight_recommendation_data.csv\"  # Replace with the path to your CSV file\n",
        "data = pd.read_csv(csv_file)"
      ],
      "metadata": {
        "id": "NHr2MIQDXHo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import pytesseract\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import joblib\n",
        "from requests.adapters import HTTPAdapter\n",
        "from requests.packages.urllib3.util.retry import Retry\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "EoTr0CRnqVdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from requests.adapters import HTTPAdapter\n",
        "from requests.packages.urllib3.util.retry import Retry\n",
        "import pytesseract\n",
        "\n",
        "# Ensure required columns are present\n",
        "required_columns = ['image_link', 'entity_name', 'entity_value']\n",
        "if not all(col in data.columns for col in required_columns):\n",
        "    raise ValueError(f\"CSV must contain columns: {', '.join(required_columns)}\")\n",
        "\n",
        "# Directory to save images\n",
        "image_dir = \"images\"\n",
        "os.makedirs(image_dir, exist_ok=True)\n",
        "\n",
        "# Configure retry strategy globally (outside the function)\n",
        "retry_strategy = Retry(\n",
        "    total=3,\n",
        "    status_forcelist=[429, 500, 502, 503, 504],\n",
        "    allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"],\n",
        "    backoff_factor=1\n",
        ")\n",
        "\n",
        "# Adjust pool size and max connections\n",
        "adapter = HTTPAdapter(\n",
        "    max_retries=retry_strategy,\n",
        "    pool_connections=100,  # Increase pool connections limit\n",
        "    pool_maxsize=100       # Increase the max number of connections in the pool\n",
        ")\n",
        "\n",
        "# Setup the session with the adjusted adapter\n",
        "http = requests.Session()\n",
        "http.mount(\"https://\", adapter)\n",
        "http.mount(\"http://\", adapter)\n",
        "\n",
        "# Pre-compile the regex pattern for efficiency\n",
        "pattern = re.compile(r\"(\\d+\\.?\\d*)\\s*([a-zA-Z]+)\")\n",
        "\n",
        "def process_image(row):\n",
        "    try:\n",
        "        image_url = row['image_link']\n",
        "        entity_name = row['entity_name']\n",
        "        entity_value = row['entity_value']\n",
        "\n",
        "        image_name = f\"image_{row.name}.jpg\"\n",
        "        save_path = os.path.join(image_dir, image_name)\n",
        "\n",
        "        # Download the image\n",
        "        response = http.get(image_url, timeout=10)\n",
        "        if response.status_code == 200:\n",
        "            img = Image.open(BytesIO(response.content))\n",
        "            img.save(save_path)\n",
        "\n",
        "            # Perform OCR on the image\n",
        "            text = pytesseract.image_to_string(img)\n",
        "\n",
        "            # Parse text to get the numerical value and unit\n",
        "            matches = pattern.findall(text)\n",
        "            parsed_text = \" \".join([\" \".join(match) for match in matches]) if matches else \"\"\n",
        "\n",
        "            return {\n",
        "                'image_path': save_path,\n",
        "                'entity_name': entity_name,\n",
        "                'entity_value': entity_value,\n",
        "                'extracted_text': text,\n",
        "                'parsed_text': parsed_text\n",
        "            }\n",
        "        else:\n",
        "            # Log failed download attempts\n",
        "            return {'error': f\"Failed to download {image_url}. Status code: {response.status_code}\"}\n",
        "\n",
        "    except Exception as e:\n",
        "        # Log exceptions instead of printing them\n",
        "        return {'error': f\"Error processing row {row.name}: {str(e)}\"}\n",
        "\n",
        "# Use ThreadPoolExecutor for parallel processing\n",
        "ocr_results = []\n",
        "with ThreadPoolExecutor(max_workers=min(20, os.cpu_count() * 2)) as executor:\n",
        "    futures = {executor.submit(process_image, row): row.name for _, row in data.iterrows()}\n",
        "\n",
        "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing Images\"):\n",
        "        result = future.result()\n",
        "        if result:\n",
        "            ocr_results.append(result)\n",
        "\n",
        "# Convert to DataFrame\n",
        "ocr_df = pd.DataFrame(ocr_results)\n",
        "\n",
        "# Filter out errors from the results if any\n",
        "ocr_df_filtered = ocr_df[ocr_df['error'].isna()]\n",
        "\n",
        "# Save OCR results to CSV for later use\n",
        "ocr_df_filtered.to_csv('ocr_results.csv', index=False)\n",
        "\n",
        "print(f\"Processed {len(ocr_df_filtered)} images out of {len(data)} total images successfully.\")"
      ],
      "metadata": {
        "id": "lEh4884GXIi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import joblib\n",
        "import spacy"
      ],
      "metadata": {
        "id": "Og5l4RXdqeoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ocr_df.head()"
      ],
      "metadata": {
        "id": "Zn5OiEwA2s1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "_df_0.groupby('image_path').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "UFKl_0lB5RzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "ocr_df = pd.read_csv('ocr_results.csv')\n",
        "\n",
        "# Step 2: Check for NaN values and drop them\n",
        "ocr_df = ocr_df.dropna(subset=['parsed_text', 'entity_value'])\n",
        "\n",
        "# Encode your labels\n",
        "ocr_df['entity_value_encoded'] = ocr_df['entity_value'].astype('category').cat.codes\n",
        "\n",
        "# Prepare the dataset\n",
        "texts = ocr_df['parsed_text'].tolist()\n",
        "labels = ocr_df['entity_value_encoded'].tolist()\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a custom Dataset class\n",
        "class EntityDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Tokenize the text\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=False,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Step 3: Initialize the tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Create DataLoader\n",
        "max_len = 128  # Maximum length of input sequences\n",
        "batch_size = 16\n",
        "\n",
        "train_dataset = EntityDataset(X_train, y_train, tokenizer, max_len)\n",
        "test_dataset = EntityDataset(X_test, y_test, tokenizer, max_len)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Step 4: Load the BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(ocr_df['entity_value_encoded'].unique()))\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Training loop\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch in range(5):  # Adjust the number of epochs as needed\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch {epoch + 1} completed. Loss: {loss.item()}')\n",
        "\n",
        "# Step 5: Testing the model\n",
        "model.eval()\n",
        "predictions, true_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        predictions.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
        "        true_labels.extend(batch['labels'].numpy())\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(true_labels, predictions))"
      ],
      "metadata": {
        "id": "P6ZFHctDt5zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    if pd.isna(text):\n",
        "        return text\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple whitespace with a single space\n",
        "    text = re.sub(r'[\\x00-\\x1f\\x7f-\\x9f]', '', text)  # Remove non-printable characters\n",
        "    return text.strip()\n",
        "\n",
        "# Load the OCR results CSV file\n",
        "ocr_results_path = 'path_to_your_ocr_results.csv'\n",
        "ocr_results_df = pd.read_csv(ocr_results_path)\n",
        "\n",
        "# Clean the extracted_text and parsed_text columns\n",
        "ocr_results_df['clean_extracted_text'] = ocr_results_df['extracted_text'].apply(clean_text)\n",
        "ocr_results_df['clean_parsed_text'] = ocr_results_df['parsed_text'].apply(clean_text)\n",
        "\n",
        "# Display the cleaned data\n",
        "print(ocr_results_df[['image_path', 'entity_name', 'entity_value', 'clean_extracted_text', 'clean_parsed_text']].head())\n"
      ],
      "metadata": {
        "id": "LP-m1j6Mqvpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Testing the model\n",
        "model.eval()\n",
        "predictions, true_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        predictions.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
        "        true_labels.extend(batch['labels'].numpy())\n",
        "\n",
        "# Calculate accuracy and F1 score\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(true_labels, predictions))\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predictions)\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mZfqXcML9BTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    if pd.isna(text):\n",
        "        return text\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple whitespace with a single space\n",
        "    text = re.sub(r'[\\x00-\\x1f\\x7f-\\x9f]', '', text)  # Remove non-printable characters\n",
        "    return text.strip()\n",
        "\n",
        "# Load the OCR results CSV file\n",
        "ocr_results_path = '/content/ocr_results.csv'\n",
        "ocr_results_df = pd.read_csv(ocr_results_path)\n",
        "\n",
        "# Clean the extracted_text and parsed_text columns\n",
        "ocr_results_df['clean_extracted_text'] = ocr_results_df['extracted_text'].apply(clean_text)\n",
        "ocr_results_df['clean_parsed_text'] = ocr_results_df['parsed_text'].apply(clean_text)\n",
        "\n",
        "# Display the cleaned data\n",
        "print(ocr_results_df[['image_path', 'entity_name', 'entity_value', 'clean_extracted_text', 'clean_parsed_text']].head())\n"
      ],
      "metadata": {
        "id": "7NhnJcxx4n4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "\n",
        "# Initialize a blank spaCy model\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "# Function to create training data in the format required by spaCy\n",
        "def create_training_data(df):\n",
        "    training_data = []\n",
        "    for index, row in df.iterrows():\n",
        "        text = row['clean_extracted_text']\n",
        "        entities = []\n",
        "        if pd.notna(row['entity_value']):\n",
        "            entity_value = str(row['entity_value'])\n",
        "            start_index = text.find(entity_value)\n",
        "            if start_index != -1:\n",
        "                end_index = start_index + len(entity_value)\n",
        "                entities.append((start_index, end_index, row['entity_name']))\n",
        "        training_data.append((text, {\"entities\": entities}))\n",
        "    return training_data\n",
        "\n",
        "training_data = create_training_data(ocr_results_df)\n",
        "\n",
        "# Convert the training data to spaCy's DocBin format\n",
        "doc_bin = DocBin()\n",
        "for text, annotations in training_data:\n",
        "    doc = nlp.make_doc(text)\n",
        "    ents = []\n",
        "    for start, end, label in annotations.get('entities'):\n",
        "        span = doc.char_span(start, end, label=label)\n",
        "        if span is not None:\n",
        "            ents.append(span)\n",
        "    doc.ents = ents\n",
        "    doc_bin.add(doc)\n",
        "\n",
        "# Save the training data to a file\n",
        "doc_bin.to_disk(\"training_data.spacy\")\n"
      ],
      "metadata": {
        "id": "jSFBjVZo42im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.training.example import Example\n",
        "from spacy.util import minibatch, compounding\n",
        "import random\n",
        "\n",
        "# Load the training data\n",
        "doc_bin = DocBin().from_disk(\"training_data.spacy\")\n",
        "docs = list(doc_bin.get_docs(nlp.vocab))\n",
        "\n",
        "# Add the NER component to the pipeline if it's not already present\n",
        "if \"ner\" not in nlp.pipe_names:\n",
        "    ner = nlp.add_pipe(\"ner\", last=True)\n",
        "else:\n",
        "    ner = nlp.get_pipe(\"ner\")\n",
        "\n",
        "# Add the labels to the NER component\n",
        "for _, annotations in training_data:\n",
        "    for start, end, label in annotations.get('entities'):\n",
        "        ner.add_label(label)\n",
        "\n",
        "# Convert the training data to Example objects\n",
        "examples = []\n",
        "for doc, (text, annotations) in zip(docs, training_data):\n",
        "    example = Example.from_dict(doc, annotations)\n",
        "    examples.append(example)\n",
        "\n",
        "# Disable other pipes during training to train only NER\n",
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
        "with nlp.disable_pipes(*other_pipes):\n",
        "    optimizer = nlp.begin_training()\n",
        "    for itn in range(100):  # Number of training iterations\n",
        "        random.shuffle(examples)\n",
        "        losses = {}\n",
        "        batches = minibatch(examples, size=compounding(4.0, 32.0, 1.001))\n",
        "        for batch in batches:\n",
        "            nlp.update(batch, drop=0.5, losses=losses)\n",
        "        print(\"Losses\", losses)\n",
        "\n",
        "# Save the trained model\n",
        "nlp.to_disk(\"ner_model\")\n"
      ],
      "metadata": {
        "id": "ZNk8DMV8B2N_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.training.example import Example\n",
        "from spacy.util import minibatch, compounding\n",
        "import random\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the training data\n",
        "doc_bin = DocBin().from_disk(\"training_data.spacy\")\n",
        "docs = list(doc_bin.get_docs(nlp.vocab))\n",
        "\n",
        "# Add the NER component to the pipeline if it's not already present\n",
        "if \"ner\" not in nlp.pipe_names:\n",
        "    ner = nlp.add_pipe(\"ner\", last=True)\n",
        "else:\n",
        "    ner = nlp.get_pipe(\"ner\")\n",
        "\n",
        "# Add the labels to the NER component\n",
        "for _, annotations in training_data:\n",
        "    for start, end, label in annotations.get('entities'):\n",
        "        ner.add_label(label)\n",
        "\n",
        "# Convert the training data to Example objects\n",
        "examples = []\n",
        "for doc, (text, annotations) in zip(docs, training_data):\n",
        "    example = Example.from_dict(doc, annotations)\n",
        "    examples.append(example)\n",
        "\n",
        "# Split into training and validation sets\n",
        "split = int(len(examples) * 0.8)\n",
        "train_examples = examples[:split]\n",
        "val_examples = examples[split:]\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, examples):\n",
        "    preds = []\n",
        "    trues = []\n",
        "    for example in examples:\n",
        "        pred = model(example.text)\n",
        "        preds.extend([(ent.text, ent.label_) for ent in pred.ents])\n",
        "        trues.extend([(ent.text, ent.label_) for ent in example.reference.ents])\n",
        "    return classification_report(trues, preds, output_dict=True)\n",
        "\n",
        "# Disable other pipes during training to train only NER\n",
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
        "with nlp.disable_pipes(*other_pipes):\n",
        "    optimizer = nlp.begin_training()\n",
        "    for itn in range(100):  # Number of training iterations\n",
        "        random.shuffle(train_examples)\n",
        "        losses = {}\n",
        "        batches = minibatch(train_examples, size=compounding(4.0, 32.0, 1.001))\n",
        "        for batch in batches:\n",
        "            nlp.update(batch, drop=0.5, losses=losses)\n",
        "        print(f\"Iteration {itn+1}: Losses\", losses)\n",
        "\n",
        "        # Evaluate the model every 10 iterations\n",
        "        if (itn + 1) % 10 == 0:\n",
        "            metrics = evaluate_model(nlp, val_examples)\n",
        "            print(f\"Iteration {itn+1}: Evaluation Metrics\")\n",
        "            print(metrics)\n",
        "\n",
        "# Save the trained model\n",
        "nlp.to_disk(\"ner_model\")\n"
      ],
      "metadata": {
        "id": "Uy00VzzEB6Rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the trained model\n",
        "nlp = spacy.load(\"ner_model\")\n",
        "\n",
        "# Evaluate the final model on the validation set\n",
        "metrics = evaluate_model(nlp, val_examples)\n",
        "print(\"Final Evaluation Metrics\")\n",
        "print(metrics)\n",
        "\n",
        "# Detailed classification report\n",
        "report = classification_report([ent[1] for ent in metrics], [ent[1] for ent in metrics], output_dict=False)\n",
        "print(report)\n",
        "\n",
        "# Test the model on new text\n",
        "test_text = \"The product weight is 12.0 ounce.\"\n",
        "doc = nlp(test_text)\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)\n"
      ],
      "metadata": {
        "id": "6EbL1ftlCf77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8y64IZgxCwYQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}